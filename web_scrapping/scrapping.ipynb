{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Web Scrapping con BeautifulSoup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión BeautifulSoup: 4.11.1\n",
      "Versión Requests: 2.31.0\n"
     ]
    }
   ],
   "source": [
    "# Versiones\n",
    "import bs4 # Solo para chequeo\n",
    "print(f'Versión BeautifulSoup: {bs4.__version__}')\n",
    "print(f'Versión Requests: {requests.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos el Scrapping\n",
    "# 1. Obtener el enlace\n",
    "URL_BASE = 'https://scrapepark.org/'\n",
    "pedido_obtenido = requests.get(URL_BASE)\n",
    "html_obtenido = pedido_obtenido.text\n",
    "\n",
    "# 2. \"Parsear\" HTML\n",
    "soup = BeautifulSoup(html_obtenido, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **El método `.find()`**\n",
    "\n",
    "Nos permite quedarnos con la información asociada a una etiqueta de HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2>¿Por qué comprar con nosotros?</h2>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primer_h2 = soup.find('h2')\n",
    "primer_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¿Por qué comprar con nosotros?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solo el texto\n",
    "primer_h2.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **El método `.find_all()`**\n",
    "\n",
    "Busca **TODOS** los elementos de la página con esa etiqueta y devuelve una \"lista\" que los contiene (en realidad devuelve un objeto de la clase *bs4.element.ResultSet*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2>¿Por qué comprar con nosotros?</h2>,\n",
       " <h2>\n",
       "                   #<span>Novedades</span>\n",
       " </h2>,\n",
       " <h2>Nuestros productos</h2>,\n",
       " <h2>Testimonios de clientes</h2>,\n",
       " <h2 class=\"heading-container\">Precios</h2>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2_todos = soup.find_all('h2')\n",
    "h2_todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2>¿Por qué comprar con nosotros?</h2>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARGUMENTOS\n",
    "# Si usamos el parámetro limit=1, emulamos al método .find()\n",
    "h2_uno_solo = soup.find_all('h2', limit=1)\n",
    "h2_uno_solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Por qué comprar con nosotros?\n",
      "\n",
      "                  #Novedades\n",
      "\n",
      "Nuestros productos\n",
      "Testimonios de clientes\n",
      "Precios\n"
     ]
    }
   ],
   "source": [
    "# Podemos iterar sobre el objeto\n",
    "for seccion in h2_todos:\n",
    "    print(seccion.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Por qué comprar con nosotros?\n",
      "#Novedades\n",
      "Nuestros productos\n",
      "Testimonios de clientes\n",
      "Precios\n"
     ]
    }
   ],
   "source": [
    "# get_text() para mas funcionalidades\n",
    "for seccion in h2_todos:\n",
    "    print(seccion.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Utilizando atributos de las etiquetas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"heading-container heading-center\" id=\"about\">\n",
      "<h2>¿Por qué comprar con nosotros?</h2>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\" id=\"products\">\n",
      "<h2>Nuestros productos</h2>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\">\n",
      "<h3>Suscríbete para obtener descuentos y ofertas</h3>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\">\n",
      "<h2>Testimonios de clientes</h2>\n",
      "</div>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Clase\n",
    "divs = soup.find_all('div', class_ = \"heading-container heading-center\")\n",
    "\n",
    "for div in divs:\n",
    "    print(div)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"Parque de patinaje\" src=\"../images/slider-bg.jpg\"/>\n",
      "<img alt=\"Patineta\" src=\"../images/p2.jpg\"/>\n"
     ]
    }
   ],
   "source": [
    "# Todas las etiquetas que tengan el artibuto \"src\"\n",
    "src_todos = soup.find_all(src=True)\n",
    "\n",
    "for elemento in src_todos:\n",
    "    if elemento['src'].endswith(\".jpg\"):\n",
    "        print(elemento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Descargando contenido**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¡¡¡CORRER ESTA CELDA DESCARGA TODAS LAS IMAGENES DEL SITIO!!!\n",
    "# Ejercicio: Descargar todas las imágenes\n",
    "url_imagenes = []\n",
    "\n",
    "for i, img in enumerate(src_todos):\n",
    "\n",
    "    if img['src'].endswith(\".png\"):\n",
    "\n",
    "        print(img['src'])\n",
    "        r = requests.get(f\"{URL_BASE}{img['src']}\")\n",
    "\n",
    "        with open(f'img_{i}.png', 'wb') as f:\n",
    "            f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Etiquetas iframe y table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Longboard', '$80', '$85', '$90', '$62', '$150']\n"
     ]
    }
   ],
   "source": [
    "# Información de tablas\n",
    "URL_TABLA = soup.find_all('iframe')[0]['src']\n",
    "\n",
    "request_tabla = requests.get(f'{URL_BASE}{URL_TABLA}')\n",
    "\n",
    "html_tabla = request_tabla.text\n",
    "soup_tabla = BeautifulSoup(html_tabla, 'html.parser')\n",
    "soup_tabla.find('table')\n",
    "\n",
    "#Los modelos faltantes se muestran en color rojo en la tabla\n",
    "productos_faltantes = soup_tabla.find_all(['th', 'td'], attrs={'style': 'color: red;'})\n",
    "productos_faltantes = [talle.text for talle in productos_faltantes]\n",
    "\n",
    "print(productos_faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producto: New Skateboard1  | precio: 75\n",
      "producto: Used Skateboard2 | precio: 80\n",
      "producto: New Skateboard3  | precio: 68\n",
      "producto: Used Skateboard4 | precio: 70\n",
      "producto: New Skateboard5  | precio: 75\n",
      "producto: New Skateboard6  | precio: 58\n",
      "producto: New Skateboard7  | precio: 80\n",
      "producto: New Skateboard8  | precio: 35\n",
      "producto: New Skateboard9  | precio: 165\n",
      "producto: Used Skateboard10 | precio: 54\n",
      "producto: Used Skateboard11 | precio: 99\n",
      "producto: New Skateboard12 | precio: 110\n"
     ]
    }
   ],
   "source": [
    "divs = soup.find_all('div', class_='detail-box')\n",
    "productos = []\n",
    "precios = []\n",
    "\n",
    "for div in divs:\n",
    "    if (div.h6 is not None) and ('Skateboard' in div.h5.text):\n",
    "        producto = div.h5.get_text(strip=True)\n",
    "        precio = div.h6.get_text(strip=True).replace('$', '')\n",
    "        # Se pueden agregar filtros\n",
    "        print(f'producto: {producto:<16} | precio: {precio}')\n",
    "        productos.append(producto)\n",
    "        precios.append(precio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cambios que dependen de la URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scrapepark.org/contact1\n",
      "Text that changes between pages in contact 1 :)\n",
      "https://scrapepark.org/contact2\n",
      "Text that changes between pages in contact 2 :)\n"
     ]
    }
   ],
   "source": [
    "URL_BASE = 'https://scrapepark.org/contact'\n",
    "\n",
    "for i in range(1, 3):\n",
    "    URL_FINAL = f\"{URL_BASE}{i}\"\n",
    "    print(URL_FINAL)\n",
    "    r = requests.get(URL_FINAL)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    print(soup.h5.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Datos que no sabemos en qué parte de la página se encuentran**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[': 4-444-4444']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expresiones regulares\n",
    "import re\n",
    "\n",
    "# 1. Obtener el HTML\n",
    "URL_BASE = 'https://scrapepark.org'\n",
    "pedido_obtenido = requests.get(URL_BASE)\n",
    "html_obtenido = pedido_obtenido.text\n",
    "\n",
    "# 2. \"Parsear\" el HTML\n",
    "soup = BeautifulSoup(html_obtenido, \"html.parser\")\n",
    "\n",
    "telefonos = soup.find_all(string=re.compile(\"\\d+-\\d+-\\d+\"))\n",
    "telefonos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sales@mail.com']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = soup.find_all(string=re.compile(\"[a-zA-Z0-9]+(?:\\.[a-zA-Z0-9]+)*@[a-zA-z0-9]+(?:\\.[a-zA-Z0-9]+)*$\"))\n",
    "emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Moviéndonos por el árbol**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['© 2022 ']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copyrights = soup.find_all(string=re.compile(\"©\"))\n",
    "copyrights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>© 2022 <span>All Rights Reserved</span>.\n",
       "        <a href=\"https://html.design/\" rel=\"noopener noreferrer\" target=\"_blank\">Created with Free Html Templates</a>.\n",
       "      </p>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primer_copyright = copyrights[0]\n",
    "primer_copyright.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3 class=\"menu\">MENU</h3>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu = soup.find(string=re.compile(\"MENU\"))\n",
    "menu.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul>\n",
       " <li><a href=\"#\">Home</a></li>\n",
       " <li><a href=\"#\">About</a></li>\n",
       " <li><a href=\"#\">Services</a></li>\n",
       " <li><a href=\"#\">Testimonials</a></li>\n",
       " <li><a href=\"#\">Contact</a></li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu.parent.find_next_siblings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comentário sobre excepciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENU\n",
      "© 2022 \n",
      "El string 'Carpincho' no fue encontrado.\n",
      "New Skateboard\n"
     ]
    }
   ],
   "source": [
    "strings_a_buscar = [\"MENU\", \"©\", \"Carpincho\", \"Skateboard\"]\n",
    "\n",
    "for string in strings_a_buscar:\n",
    "    try:\n",
    "        resultado = soup.find(string=re.compile(string))\n",
    "        print(resultado.text)\n",
    "    except AttributeError:\n",
    "        print(f\"El string '{string}' no fue encontrado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Almacenamiento de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "productos.insert(0, \"productos\")\n",
    "precios.insert(0, \"precios\")\n",
    "datos = dict(zip(productos, precios))\n",
    "\n",
    "with open('datos.csv', 'w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(datos.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrap-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
